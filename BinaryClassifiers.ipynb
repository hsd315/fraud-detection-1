{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(7)\n",
    "df=pd.read_csv(\"data.csv\")\n",
    "\n",
    "fr0 = df[df[\"Class\"] == 0].sample( n=492 ).copy()\n",
    "fr1 = df[df[\"Class\"] == 1].copy()\n",
    "\n",
    "drop_arr = [ \"Time\", \"V13\", \"V15\", \"V24\", \"V25\" ]\n",
    "#drop_arr = [ \"Time\" ]\n",
    "\n",
    "df=pd.concat([fr0, fr1]).drop(drop_arr, 1)\n",
    "\n",
    "# prepare data for binary classification. I don't want them to be structured, so let's shuffle them\n",
    "\n",
    "inp = df.drop([\"Amount\", \"Class\"], 1).values\n",
    "fra = df[\"Class\"].values\n",
    "\n",
    "ind = np.random.permutation(fra.size)\n",
    "\n",
    "inp = inp[ind]\n",
    "fra = fra[ind]\n",
    "\n",
    "# prepare data for amount prediction\n",
    "\n",
    "ami = df[df[\"Class\"] == 1].drop([\"Amount\", \"Class\"], 1).values\n",
    "amo = df[df[\"Class\"] == 1][\"Amount\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score\n",
    "\n",
    "kf = KFold( n_splits = 4, shuffle = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Support Vector Classification</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.1\tKernel: linear\tRecall: 0.97\tAccuracy 0.93\tF1 Score 0.93\n",
      "C: 0.1\tKernel: poly\tRecall: 0.99\tAccuracy 0.92\tF1 Score 0.92\n",
      "C: 0.1\tKernel: rbf\tRecall: 0.91\tAccuracy 0.91\tF1 Score 0.91\n",
      "C: 1.0\tKernel: linear\tRecall: 0.96\tAccuracy 0.93\tF1 Score 0.93\n",
      "C: 1.0\tKernel: poly\tRecall: 0.98\tAccuracy 0.94\tF1 Score 0.93\n",
      "C: 1.0\tKernel: rbf\tRecall: 0.94\tAccuracy 0.93\tF1 Score 0.92\n",
      "C: 10.0\tKernel: linear\tRecall: 0.96\tAccuracy 0.93\tF1 Score 0.93\n",
      "C: 10.0\tKernel: poly\tRecall: 0.94\tAccuracy 0.92\tF1 Score 0.92\n",
      "C: 10.0\tKernel: rbf\tRecall: 0.91\tAccuracy 0.92\tF1 Score 0.92\n",
      "C: 80.0\tKernel: linear\tRecall: 0.95\tAccuracy 0.93\tF1 Score 0.93\n",
      "C: 80.0\tKernel: poly\tRecall: 0.92\tAccuracy 0.91\tF1 Score 0.90\n",
      "C: 80.0\tKernel: rbf\tRecall: 0.90\tAccuracy 0.91\tF1 Score 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "for C_par in [ 0.1, 1, 10, 80 ]:\n",
    "    for ker_par in [ \"linear\", \"poly\", \"rbf\" ]:\n",
    "        \n",
    "        rec_res, acc_res, f1_res = [], [], []\n",
    "        \n",
    "        for train_index, test_index in kf.split( inp ):\n",
    "            xtrain, xtest = inp[train_index], inp[test_index]\n",
    "            ytrain, ytest = fra[train_index], fra[test_index]\n",
    "            \n",
    "            svc_cl = svm.SVC( kernel = ker_par, C = C_par )\n",
    "            \n",
    "            svc_cl.fit( xtrain, ytrain )\n",
    "            \n",
    "            ypred = svc_cl.predict( xtest )\n",
    "            \n",
    "            rec_res.append( recall_score( ypred, ytest ) )\n",
    "            acc_res.append( accuracy_score( ypred, ytest ) )\n",
    "            f1_res.append( f1_score( ypred, ytest ) )\n",
    "            \n",
    "        print( \"C: %.1f\\tKernel: %s\\tRecall: %.2f\\tAccuracy %.2f\\tF1 Score %.2f\" %\n",
    "             ( C_par, ker_par, np.mean( rec_res ), np.mean( acc_res ), np.mean( f1_res ) )\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Decision Tree</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 3\tRecall: 0.94\tAccuracy 0.91\tF1 Score 0.91\n",
      "Depth: 4\tRecall: 0.93\tAccuracy 0.92\tF1 Score 0.92\n",
      "Depth: 5\tRecall: 0.95\tAccuracy 0.92\tF1 Score 0.92\n",
      "Depth: 6\tRecall: 0.95\tAccuracy 0.93\tF1 Score 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for depth in [ 3, 4, 5, 6 ]:\n",
    "    rec_res, acc_res, f1_res = [], [], []\n",
    " \n",
    "    for train_index, test_index in kf.split( inp ):\n",
    "        xtrain, xtest = inp[train_index], inp[test_index]\n",
    "        ytrain, ytest = fra[train_index], fra[test_index]\n",
    "        \n",
    "        dtree = DecisionTreeClassifier( max_depth = depth )\n",
    "          \n",
    "        dtree.fit( xtrain, ytrain )\n",
    "            \n",
    "        ypred = dtree.predict( xtest )\n",
    "            \n",
    "        rec_res.append( recall_score( ypred, ytest ) )\n",
    "        acc_res.append( accuracy_score( ypred, ytest ) )\n",
    "        f1_res.append( f1_score( ypred, ytest ) )\n",
    "        \n",
    "    print(\"Depth: %d\\tRecall: %.2f\\tAccuracy %.2f\\tF1 Score %.2f\" %\n",
    "        ( depth, np.mean( rec_res ), np.mean( acc_res ), np.mean( f1_res ) )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.010\tRecall: 0.95\tAccuracy 0.93\tF1 Score 0.93\n",
      "C: 0.100\tRecall: 0.97\tAccuracy 0.94\tF1 Score 0.94\n",
      "C: 0.200\tRecall: 0.96\tAccuracy 0.93\tF1 Score 0.93\n",
      "C: 0.300\tRecall: 0.97\tAccuracy 0.94\tF1 Score 0.93\n",
      "C: 1.000\tRecall: 0.97\tAccuracy 0.94\tF1 Score 0.94\n",
      "C: 10.000\tRecall: 0.97\tAccuracy 0.94\tF1 Score 0.93\n",
      "C: 80.000\tRecall: 0.95\tAccuracy 0.93\tF1 Score 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "for C_par in [ 0.01, 0.1, 0.2, 0.3, 1, 10, 80 ]:\n",
    "    rec_res, acc_res, f1_res = [], [], []\n",
    " \n",
    "    for train_index, test_index in kf.split( inp ):\n",
    "        xtrain, xtest = inp[train_index], inp[test_index]\n",
    "        ytrain, ytest = fra[train_index], fra[test_index]\n",
    "        \n",
    "        log_re = LogisticRegression( C = C_par, n_jobs = 2 )\n",
    "          \n",
    "        log_re.fit( xtrain, ytrain )\n",
    "            \n",
    "        ypred = log_re.predict( xtest )\n",
    "            \n",
    "        rec_res.append( recall_score( ypred, ytest ) )\n",
    "        acc_res.append( accuracy_score( ypred, ytest ) )\n",
    "        f1_res.append( f1_score( ypred, ytest ) )\n",
    "        \n",
    "    print(\"C: %.3f\\tRecall: %.2f\\tAccuracy %.2f\\tF1 Score %.2f\" %\n",
    "        ( C_par, np.mean( rec_res ), np.mean( acc_res ), np.mean( f1_res ) )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
